Introducción

La nueva serie de modelosGemini 3de Google (Pro y Flash) promete mejoras sustanciales en razonamiento, multimodalidad y velocidad. Sin embargo, su integración en la extensión LIA (que utiliza la API generativa de Google) ha presentado dificultades: llamadas al endpoint de streaming con**gemini-3-pro**están devolviendo errores 404. Esto sugiere posibles problemas de disponibilidad o uso incorrecto de la API para estos modelos de tercera generación. A continuación, investigamos la disponibilidad deGemini 3 ProyGemini 3 Flashen las distintas versiones de la API (v1beta y v1 estable), si soportan los métodos de generación de contenido estándar y en streaming, qué cambios de invocación existen respecto a la generación anterior (Gemini 2.x), y qué restricciones o requerimientos conocidos pueden estar causando los errores. Finalmente, ofreceremos una guía para ajustar la extensión LIA, incluyendo recomendaciones sobre cambios de configuración (modelos, endpoints, cabeceras) y sugeriremos qué modelo conviene usar por defecto considerando compatibilidad y disponibilidad actuales.

Hallazgos Principales

Disponibilidad en la API:Los modelosGemini 3 ProyGemini 3 Flashse encuentranen vista previa (preview)dentro de la API generativa. Están soportados en la versión v1beta de la API (y accesibles también vía la ruta v1 estable en la práctica), pero requieren el uso del identificador correcto del modelo incluyendo el sufijo “**-preview**”[[1]](https://ai.google.dev/gemini-api/docs/gemini-3#:~:text=REST).

Soporte de métodos:Ambos modelos admiten el método estándar**generateContent**para generación completa y tambiénstreamingmediante**streamGenerateContent**(usando Server-Sent Events)[[2]](https://ai.google.dev/api#:~:text=,time%20conversational%20use%20cases), así como un API “en vivo” vía WebSocket (**BidiGenerateContent**). El error 404 proviene de queGemini 3no responde a llamadas de streaming en v1beta sin la configuración adecuada o sin acceso habilitado.

Cambios de invocación vs Gen 2.0:En comparación con modelos Gemini 2.x, los nuevos modelos requieren especificar sus nombres exactos (por ej.,**"gemini-3-pro-preview"**en lugar de antiguos alias genéricos) y algunos endpoints o parámetros han cambiado. Por ejemplo,Gemini 3unifica la generación de chat y contenido en**generateContent**, y utilizathinking_levelen vez de configuraciones previas para el razonamiento. Además, ciertostoolsno están soportados (p. ej. no hay soporte deMapsniComputer Useintegrados en Gemini 3 aún[[3]](https://ai.google.dev/gemini-api/docs/gemini-3#:~:text=1.5%20.%20,calling%20is%20not%20yet%20supported)).

Restricciones conocidas:Gemini 3 Pronoestá disponible para todos los usuarios por defecto – requiere una suscripciónGoogle AI Ultrao tener habilitado un API key de pago (Blaze plancon billing)[[4]](https://github.com/google-gemini/gemini-cli/discussions/13280#:~:text=Gemini%203%20Pro%20is%20available,now%20in%20Gemini%20CLI%20for)[[5]](https://ai.google.dev/gemini-api/docs/gemini-3#:~:text=2,to%2064k%20tokens%20of%20output). En cambio,Gemini 3 Flashes más accesible: Google ofrece unnivel gratuitopara Flash en la API developer[[5]](https://ai.google.dev/gemini-api/docs/gemini-3#:~:text=2,to%2064k%20tokens%20of%20output), lo que significa que debería estar disponible para desarrolladores con clave API estándar, aunque su lanzamiento ha sido gradual. De hecho, reportes iniciales mostraron errores 404 conFlashen v1beta[[6]](https://www.reddit.com/r/Bard/comments/1popdps/gemini3flashpreview_is_the_model_id_i_tried_in_on/#:~:text=ClientError%3A%20got%20status%3A%20404%20Not,NOT_FOUND)hasta que se habilitó su acceso general. También es sabido que actualmenteGemini 3solo está disponible en ciertos entornos (p. ej. API de desarrolladores y Vertex AI) para usuarios autorizados, y llamados con una clave sin permisos resultan en 404 (“Requested entity was not found”).

Adaptación de la extensión LIA:Para soportar Gemini 3 correctamente, se debe usar elnombre de modelo correcto(incluyendo “**-preview**”) y posiblemente actualizar la versión de la API utilizada. La extensión debería invocar los endpoints de modelo como**.../models/gemini-3-pro-preview:generateContent**o**:streamGenerateContent**según corresponda[[1]](https://ai.google.dev/gemini-api/docs/gemini-3#:~:text=REST). Es recomendablecambiar el modelo por defecto a Gemini 3 Flash(por su coste menor y amplia disponibilidad) y usar Gemini 3 Pro como respaldo para quienes tengan acceso Ultra o necesiten capacidades máximas. Asimismo, se sugiere actualizar la librería de la API (@google/generative-ai) a la versión más reciente (≥0.4.x) que conozca estos modelos, y utilizar preferentemente la versiónv1 establede la API en lugar de v1beta para evitar incompatibilidades de producción. También se debe verificar incluir laAPI keyen la cabecera**x-goog-api-key**y cualquier otro ajuste (e.g.**?alt=sse**para SSE streaming) que la API requiera para streaming.

Detalles Técnicos y Específicos

Disponibilidad deGemini 3 ProyFlashen la API (v1beta vs v1)

Google introdujo los modelos Gemini 3 a través de suGemini APIpara desarrolladores a fines de 2025, inicialmente en versiónpreview. En la documentación oficial se destaca que“todos los modelos Gemini 3 están actualmente en vista previa”[[7]](https://ai.google.dev/gemini-api/docs/gemini-3#:~:text=Nano%20Banana%20Pro%20,quality%20image%20generation%20model%20yet). Esto implica que, por ahora, forman parte de laAPI v1betade Generative Language, aunque también existen endpoints equivalentes en la ruta v1 estable. De hecho, los ejemplos oficiales siguen usando la ruta**v1beta**en las llamadas cURL[[1]](https://ai.google.dev/gemini-api/docs/gemini-3#:~:text=REST)(posiblemente porque la API aún se considera beta para estas funciones). No obstante, desarrolladores han reportado que es preferible utilizar la versión v1 estable para producción, ya que v1beta podría deprecarse[[8]](https://github.com/langgenius/dify/discussions/17263#:~:text=4). En la práctica, llamar a**v1**o**v1beta**con un modelo válido y clave adecuada resulta equivalente si el modelo está disponible para tu proyecto.

Escrítico usar el nombre exacto del modeloen la URL. ParaGemini 3 Proel ID es**"gemini-3-pro-preview"**y paraGemini 3 Flashes**"gemini-3-flash-preview"**. Por ejemplo, una invocación REST correcta sería:

**POST https://generativelanguage.googleapis.com/v1beta/models/gemini-3-pro-preview:generateContent **
H: x-goog-api-key: YOUR_KEY
{ "contents": [ ... ] }

Tal como se muestra en la guía oficial[[1]](https://ai.google.dev/gemini-api/docs/gemini-3#:~:text=REST). Si se omite el sufijo “**-preview**” o se usa un nombre incorrecto (**gemini-3-pro**a secas), la API no encontrará el modelo y retornará 404. En el código de LIA, asegurarse de que**MODELS.PRIMARY**y**MODELS.FALLBACK**estén configurados con esos valores exactos (lo cual, según el fragmento de**config.ts**, ya está:**"gemini-3-flash-preview"**y**"gemini-3-pro-preview"**). Hay que verificar que en las llamadas efectivas el sufijo no se pierda.

Al momento de la introducción de Gemini 3, Google limitó el acceso de estos modelos. Documentación de la comunidad indica que inicialmente“Gemini 3 solo está disponible para usuariosAI Ultra(y API keys de pago) y requiere unirse a la lista de espera para otros”[[4]](https://github.com/google-gemini/gemini-cli/discussions/13280#:~:text=Gemini%203%20Pro%20is%20available,now%20in%20Gemini%20CLI%20for)[[9]](https://github.com/google-gemini/gemini-cli/discussions/13280#:~:text=%E2%8F%B3Waitlist). Esto significa que, aunque el endpoint exista, un 404 puede significarfalta de permisopara usar ese modelo con tu clave. Efectivamente, en enero de 2026 Google comunicó queGemini 3 Proestá disponible inmediatamente para suscriptores Ultra y para “usuarios con API key de pago”, mientras que los demás deben esperar[[4]](https://github.com/google-gemini/gemini-cli/discussions/13280#:~:text=Gemini%203%20Pro%20is%20available,now%20in%20Gemini%20CLI%20for). Por tanto,tener la API key vinculada a un proyecto con facturación habilitada (plan Blaze)es esencial para usar3 Pro. En cambio,Gemini 3 Flashse concibió como un modelo más accesible; según la FAQ oficial,“Gemini 3 Flash (gemini-3-flash-preview) tiene un nivel gratuito en la API (...), no hay nivel gratuito para gemini-3-pro-preview”[[5]](https://ai.google.dev/gemini-api/docs/gemini-3#:~:text=2,to%2064k%20tokens%20of%20output). Esto indica que Flash debería estar disponible incluso sin suscripción Ultra, permitiendo a los desarrolladores probarlo con su clave estándar (sujeto a cuotas gratuitas). De hecho,Gemini 3 Flashfue anunciado como ofrecer“inteligencia de nivel Pro a la velocidad y costo de Flash”[[10]](https://ai.google.dev/gemini-api/docs/gemini-3#:~:text=Gemini%203%20Pro%2C%20the%20first,and%20advanced%20reasoning%20across%20modalities), haciéndolo ideal como modelo por defecto.

Cabe destacar que la disponibilidad de Flash en la API de desarrolladores ocurrió un poco después que Pro. A finales de 2025, usuarios reportaron que invocar**gemini-3-flash-preview**en la API devolvía“not found for API version v1beta”[[11]](https://www.reddit.com/r/Bard/comments/1popdps/gemini3flashpreview_is_the_model_id_i_tried_in_on/#:~:text=ClientError%3A%20got%20status%3A%20404%20Not,NOT_FOUND), sugiriendo que su activación general aún no estaba completa. La recomendación temporal fue usar Vertex AI (el servicio en Google Cloud) donde Flash ya funcionaba[[12]](https://www.reddit.com/r/Bard/comments/1popdps/gemini3flashpreview_is_the_model_id_i_tried_in_on/#:~:text=%E2%80%A2%20%2028d%20ago). Para enero de 2026, tras anuncios oficiales,Gemini 3 Flashquedó habilitado en la API estándar con un free tier. Si tu extensión aún recibe 404 para Flash, es posible que la clave API no tenga habilitado elproyecto de Google Generative Language con la cuota correspondiente. Asegúrate de haber actualizado tu clave desde Google AI Studio y de tener laAPI Generativahabilitada en Google Cloud para tu proyecto. Ejecutar una llamada a**models?key=API_KEY**(endpoint ListModels) puede confirmar qué modelos ve tu clave[[13]](https://github.com/langgenius/dify/discussions/17263#:~:text=Ensure%20your%20Gemini%20API%20key,Check%20available%20models%20with%3A%20bash). En resumen: en v1beta/v1 los endpoints existen para ambos modelos, pero solo responderán exitosamente si tu cuenta tiene acceso a ellos.

Soporte de**generateContent**y**streamGenerateContent**en Gemini 3

Ambos modelos Gemini 3 soportan los métodos principales de la API generativa:**generateContent**(modo estándar sin streaming) y**streamGenerateContent**(modo streaming SSE), así como elLive APIvía WebSocket bidi. La documentación de referencia del Gemini API detalla que hay tres formas de generar contenido[[14]](https://ai.google.dev/api#:~:text=The%20Gemini%20API%20is%20organized,around%20the%20following%20major%20endpoints): (1)Standard content generation(**...:generateContent**) que devuelve la respuesta completa de una vez; (2)Streaming content generation(**...:streamGenerateContent**) queutiliza SSEpara enviar por partes la respuesta[[2]](https://ai.google.dev/api#:~:text=,time%20conversational%20use%20cases); y (3)Live API (Bidi)para comunicaciones bidireccionales persistentes por WebSocket. En el contexto de LIA, el método**sendMessageStream**probablemente emplea internamente la ruta streaming SSE o la conexión WebSocket (la extensión define**LIVE_API_URL**con un endpoint**v1alpha**BidiGenerateContent[[15]](https://github.com/fernandosuarez-04/Lia-Extension/blob/9a2b3e0d19918d59a24474b4fe3c15ce915a08bd/src/config.ts#L14-L16), aunque no vimos en el código un uso directo de ese socket; es posible que la librería @google/generative-ai administre SSE bajo el capó).

Es importante confirmar queGemini 3efectivamente permite streaming. Los modelos anteriores (Gemini 2) soportaban SSE streaming añadiendo**?alt=sse**al endpoint HTTP, y eso continúa con Gemini 3. Un ejemplo de la guía oficial detext generationmuestra cómo llamar a**streamGenerateContent**con SSE[[16]](https://ai.google.dev/gemini-api/docs/text-generation#:~:text=...%20streamGenerateContent%3Falt%3Dsse%22%20%5C%20,d%20%27%7B%20%22contents). Por lo tanto,Gemini 3 ProyFlashsísoportan**streamGenerateContent**, siempre y cuando el modelo esté accesible. El error 404 observado (**models/gemini-3-pro:streamGenerateContent not found**) se debe seguramente a la combinación de problemas mencionada: nombre de modelo incorrecto o falta de acceso. Si el nombre del modelo es correcto pero la clave no tiene permisos, la API devuelveNOT_FOUNDde forma genérica (que puede confundir, ya que sugiere modelo inexistente o método no soportado, en lugar de falta de autorización).

En resumen,generateContentfunciona con ambos modelos (ejemplos oficiales disponibles[[1]](https://ai.google.dev/gemini-api/docs/gemini-3#:~:text=REST)[[17]](https://ai.google.dev/gemini-api/docs/gemini-3#:~:text=curl%20%22https%3A%2F%2Fgenerativelanguage.googleapis.com%2Fv1beta%2Fmodels%2Fgemini,%5B)) ystreamGenerateContent también, vía SSE. Para usar streaming en llamadas REST directas, hay que hacer un GET o POST al endpoint terminado en**:streamGenerateContent**con el parámetro**alt=sse**y escuchar los eventos del stream (cada evento contiene una respuesta parcial**GenerateContentResponse**). Con la librería Node (@google/generative-ai), versiones recientes ofrecen métodos como**await model.generateContentStream()**o similares, pero en la v0.24 usada podría no existir. En el código LIA actual,**chatSession.sendMessageStream()**sugiere que la librería está manejando el streaming, posiblemente vía SSE. Si esta función no reconoce correctamente los modelos 3, podría arrojar error.Actualizar la librería a una versión que soporte Gemini 3(por ejemplo,**google-generativeai**>= 0.27 o 0.30, o el renombrado**@google/genai**1.x) es aconsejable para garantizar compatibilidad.

Cabe mencionar también que Google provee unWebSocketLive API (v1alpha) para un streaming más interactivo (bi-direccional, con la posibilidad de enviar varias solicitudes en una misma sesión). Dado que LIA ya tiene configurado**BidiGenerateContent**en**LIVE_API_URL**[[15]](https://github.com/fernandosuarez-04/Lia-Extension/blob/9a2b3e0d19918d59a24474b4fe3c15ce915a08bd/src/config.ts#L14-L16), se podría usar esa vía para obtener respuestas token a token en tiempo real. Sin embargo, su uso requiere manejar la conexión WS y mensajes, por lo que si la librería ya ofrece SSE, puede ser más sencillo continuar con SSE. En cualquier caso,Gemini 3 ProyFlashsoportan ambos métodos; no existe una limitación por parte del modelo de “no soportar streamGenerateContent” – el soporte está allí, siempre que la API key tenga acceso al modelo y se use la versión correcta de la API.

Cambios en la invocación respecto a Gemini 2.0 (Generación 2.x)

Al migrar de modelos previos (ej. Gemini 2.0 o 2.5) aGemini 3, es necesario ajustar algunos identificadores y considerar ciertos cambios en parámetros:

Identificadores de modelo:En generaciones anteriores, modelos “Pro” o “Flash” podían usarse con nombres como**"gemini-2.0-pro"**o similares. En la nueva nomenclatura,todoslos modelos llevan versión explícita y sufijo preview mientras no sean GA. Por ejemplo, el modelo “Gemini Pro” ahora es**"gemini-3-pro-preview"**(y más adelante posiblemente**"gemini-3-pro"**cuando salga de preview), y “Flash” es**"gemini-3-flash-preview"**. Asegurarse de utilizar estos nombres exactos en las llamadas**getGenerativeModel**y endpoints es fundamental. En el repositorio LIA vimos que config.js define PRIMARY y FALLBACK correctamente con esos nombres[[18]](https://github.com/fernandosuarez-04/Lia-Extension/blob/9a2b3e0d19918d59a24474b4fe3c15ce915a08bd/src/config.ts#L5-L12), lo cual es correcto. Si en algún punto se pasó inadvertidamente**"gemini-3-pro"**sin “-preview”, se debe corregir.

Endpoints y métodos unificados:Mientras que en PaLM 2 o Gemini 2.0 existían métodos separados como**generateMessage**para chats y**generateText**para texto suelto, la API Gemini unifica la interacción en torno a**generateContent**. Esta función maneja chat multi-turn (pasándole un array**contents**con roles “user” y “model” para contexto) así como solicitudes de una sola vez. Por lo tanto, no es necesario (ni posible) usar endpoints antiguos como**…:generateMessage**; LIA ya usa**startChat**/**sendMessageStream**lo cual internamente utiliza**generateContent**con roles, que es correcto. La migración a Gemini 3 no requiere cambiar la lógica de chat, solo asegurarse de que los roles y partes se envíen adecuadamente en el JSON. Un ejemplo de cuerpo para chat con Gemini 3 es similar al de 2.5, especificando**"role": "user"**o**"model"**junto con**"parts": [{"text": "..."}]**[[19]](https://ai.google.dev/api#:~:text=The%20following%20shows%20a%20typical,request%20body)[[20]](https://ai.google.dev/api#:~:text=,Part%20objects%20goes%20here).

Parámetros de configuración nuevos:Gemini 3 introduce nuevos parámetros como**thinking_level**enGenerationConfig. Por defecto, Gemini 3 razona con nivel “high” (alto), lo cual puede aumentar latencia pero obtener respuestas más elaboradas. Se puede configurar**thinkingLevel: "low"**(vía**thinking_config**en JSON) para respuestas más rápidas cuando no se requiera razonamiento profundo[[21]](https://ai.google.dev/gemini-api/docs/gemini-3#:~:text=Thinking%20level)[[22]](https://ai.google.dev/gemini-api/docs/gemini-3#:~:text=response%20%3D%20client.models.generate_content%28%20model%3D%22gemini,%29%2C). Si antes se usaban hacks como cadenas de pensamiento manual (CoT) para forzar razonamiento en 2.5, ahora es preferible usar este parámetro. Asimismo,Gemini 3 Flashsoporta niveles extra (“minimal”, “medium”) que Pro no soporta[[23]](https://ai.google.dev/gemini-api/docs/gemini-3#:~:text=carefully%20reasoned), lo cual es útil para afinar rendimiento. Otro parámetro relevante es**media_resolution**para controlar resolución de procesamiento de imágenes/vídeo en entradas multimodales[[24]](https://ai.google.dev/gemini-api/docs/gemini-3#:~:text=Media%20resolution), ya que Gemini 3 maneja vision de forma más granular (p.ej.,media_resolution_highpara OCR detallado). Si LIA extensión no genera imágenes ni videos con estos modelos, esto quizá no aplique directamente, pero es bueno saberlo. En general, revisar si la extensión fija parámetros de temperatura, tokens, etc. – por ejemplo, la doc recomienda en Gemini 3no forzar temperature muy baja(dejar default 1.0) ya que en salidas deterministas podría llevar a loops[[25]](https://ai.google.dev/gemini-api/docs/gemini-3#:~:text=,document%20parsing%2C%20test%20the%20new).

Herramientas integradas (tools):Una diferencia notable es que algunostoolsque existían en Gemini 2.5 no están (aún) disponibles en Gemini 3. En la documentación se indica que“los tools de Google Maps y Computer Use no están soportados en modelos Gemini 3”[[3]](https://ai.google.dev/gemini-api/docs/gemini-3#:~:text=1.5%20.%20,calling%20is%20not%20yet%20supported). La extensión LIA aparentemente incorpora untoolde “Computer Use” (simular clicks, etc.) y lo asignaba a un modelo específico (en**MODELS.COMPUTER_USE**se ve**gemini-2.5-computer-use-preview-10-2025**[[26]](https://github.com/fernandosuarez-04/Lia-Extension/blob/9a2b3e0d19918d59a24474b4fe3c15ce915a08bd/src/config.ts#L6-L12)). Dado queGemini 3no soporta Computer Use nativamente aún, si la lógica de LIA intentara usar un modelo 3 para eso, fallaría o simplemente no funcionaría la herramienta. Una solución es seguir usando modelos 2.5 para ese caso concreto, o esperar a que habiliten Computer Use en 3. (Para contexto,Computer Usees un tool experimental para emular acciones en una computadora; su ausencia en 3 es mencionada como temporal). En cambio,Google Search,File Search,Code ExecutionyURL Contextsíestán soportados en Gemini 3[[27]](https://ai.google.dev/gemini-api/docs/gemini-3#:~:text=7,Use%20are%20currently%20not%20supported), por lo que las funciones de búsqueda web u otros que LIA incluya deberían funcionar con Gemini 3. Esto significa que la integración de LIA con la búsqueda (vimos**primaryTools**incluye**{ googleSearch: {} }**[[28]](https://github.com/fernandosuarez-04/Lia-Extension/blob/9a2b3e0d19918d59a24474b4fe3c15ce915a08bd/src/services/gemini.ts#L26-L34)) seguirá siendo compatible cuando usemos Gemini 3 Flash/Pro, ya que esas modelos permiten el uso de la herramienta de Search (de hecho, Gemini 3 fue diseñado para fluir con herramientas de agente).

Respuesta multimodal:Gemini 3también permite modalidades de respuesta combinadas (texto+imagen). La extensión LIA ya implementa**responseModalities: ["TEXT","IMAGE"]**en su función de generación de imágenes[[29]](https://github.com/fernandosuarez-04/Lia-Extension/blob/9a2b3e0d19918d59a24474b4fe3c15ce915a08bd/src/services/gemini.ts#L130-L138)usando el modelo**gemini-2.5-flash-image**. Existe un modelo dedicadoGemini 3 Pro Imagellamado**gemini-3-pro-image-preview**[[7]](https://ai.google.dev/gemini-api/docs/gemini-3#:~:text=Nano%20Banana%20Pro%20,quality%20image%20generation%20model%20yet)para generación de imágenes de alta calidad (aliasNano Banana Pro). Si se desea aprovecharlo, habría que cambiar**MODELS.IMAGE_GENERATION**a ese ID y asegurarse de que la API key tenga acceso (posiblemente está limitada como Pro). No obstante, este es un extra; el enfoque principal de la pregunta es texto. Mencionamos esto solo por completitud de “diferencias” – en general, para adaptar LIA a Gemini 3 en texto, no se necesitan cambios en la estructura de la petición más allá del nombre del modelo y considerar los nuevos parámetros si se desea.

En síntesis, respecto a la generación 2.0/2.5, loscambios clave son de nomenclatura y parámetros. Usando la librería actualizada, la transición debería ser transparente: simplemente especificar**"model": "gemini-3-flash-preview"**(o pro) en lugar del anterior. No olvidar quitar cualquier referencia obsoleta (por ejemplo, si se usaba**gemini-pro**sin número, que ya no existe) y estar atento a las recomendaciones de configuración (no setear temps muy bajas, usar thinking_level en vez de prompt engineering excesivo, etc.).

Restricciones, disponibilidad y bugs recientes

Una parte del problema observado (error 404) proviene de restricciones de disponibilidad:un 404 en la API generativa de Google a menudo significa que el modelo no está disponible para tu proyecto. A diferencia de un 401 (no autorizado) o 403 (prohibido), Google opta por responder 404Not Foundcuando intentas un modelo al que no tienes acceso, para no filtrar su existencia. Por ello, es vital confirmar que tu API key tenga las características necesarias:

Proyecto con API Generativa habilitada:Asegurarse en Google Cloud de habilitar la API “Generative Language API”. Sin esto, obtendrías errores.

Acceso a modelos Gemini 3:Como se explicó,Gemini 3 Prorequiere ser usuario Ultra ($$$) o tener la facturación activada y posiblemente solicitar acceso.Gemini 3 Flashfue liberado con tier gratis, así que en principio cualquier clave con la API habilitada debería poder usarlo (respetando límites). Google confirmó que “Gemini 3 Flash Preview tiene free tier disponible para todos vía la API”[[5]](https://ai.google.dev/gemini-api/docs/gemini-3#:~:text=2,to%2064k%20tokens%20of%20output), lo que sugiere que tras su fase inicial, no debería requerir pasos extra (aparte de quizás unirse al programa desarrollador, que ahora incluye esos beneficios para Pro/Ultra subscriptores según anuncios recientes[[30]](https://blog.google/innovation-and-ai/technology/developers-tools/gdp-premium-ai-pro-ultra/#:~:text=New%20developer%20tools%20for%20Google,Pro%20and%20Google%20AI%20Ultra)). Si aún no funciona, podría ser un retraso en la activación para tu cuenta o un bug. En ese caso, vale la pena contactar soporte o revisar foros.

Lanzamiento gradual y waitlist:Google está lanzando estas capacidades de forma controlada. Por ejemplo, la disponibilidad en herramientas de terceros y en la API fue escalonada. Hubo reportes en foros oficiales indicando“Actualmente Gemini 3 solo está disponible para usuarios AI Ultra – si no lo eres, únete a la lista de espera”[[31]](https://github.com/google-gemini/gemini-cli/issues/13284#:~:text=Fix%20Gemini%203%20,the%20waitlist%21%20thanks%20for). Esto al final de 2025 causó confusión a desarrolladores. En la práctica, a enero 2026,Gemini 3 Prosigue siendo de acceso premium (no free tier), mientrasFlashse volvió el modelo de amplio acceso.

Errores conocidos:Además del 404 por acceso, se han identificado algunos bugs específicos. Un issue reciente señaló un error 404 al enviar videos sin audio a Gemini 3 Pro[[32]](https://discuss.ai.google.dev/t/gemini-3-error-404-not-found-with-videos-without-an-audio-stream-and-media-resolution-not-set-to-high/113805#:~:text=Gemini%203%20error%20404%20NOT_FOUND,fails%20unless%20MEDIA_RESOLUTION_HIGH%20is%20set), solucionable ajustando**media_resolution_high**para forzar la lectura (puede ser irrelevante para LIA si no analiza video). Otro hilo menciona errores 400 enstreamGenerateContentcon modelosfine-tuned(tuning)[[33]](https://discuss.ai.google.dev/t/generatecontentstream-throwing-error-for-gemini-tuned-model/39169#:~:text=generateContentStream%20throwing%20error%20for%20Gemini,issue%20only%20for%20the)– esto indica que modelos ajustados (personalizados) pueden tener problemas con streaming, pero no es el caso aquí. En general, la recomendación es comprobar siempre qué modelos soporta tu clave haciendo un**GET models/**y también revisar si tu uso cumple con lasquotasyrate limits. Un error 404 puede esconder un “quota exceeded” en algunos casos (aunque típicamente sería 429). Asegúrate de que en tu cuenta de Google AI Studio, bajoAPI Keys -> Enabled Models, aparezcan Gemini 3 Pro/Flash. De lo contrario, habilítalos allí si hay opción, o solicita acceso.

Configuración de región (Vertex AI):Si en algún momento decides usar la API vía Vertex AI (usando la librería**google.cloud.aiplatform**o similar), ten en cuenta establecer la región global (**us-central1**o**global**) porque los modelos nuevos pueden no estar en todas las regiones. Un desarrollador en Reddit mencionó que al usar la librería de VertexAI tuvo que fijar región**'global'**para que funcione[[34]](https://www.reddit.com/r/Bard/comments/1popdps/gemini3flashpreview_is_the_model_id_i_tried_in_on/#:~:text=%E2%80%A2%20%2028d%20ago). Esto es relevante si LIA optara por Google Cloud endpoints en vez de la API de desarrolladores. Por ahora, parece que LIA usa la API pública (via API key), así que esto no aplica directamente, pero es bueno saberlo si se migra.

En conclusión de esta sección,no hay indicios de que los modelos Gemini 3 tengan una incompatibilidad técnica con**generateContent**/stream, sino que el problema radica en ajustes de acceso y nombres. Solucionando estos, la extensión podrá usarlos. Google misma usa Gemini 3 Flash/Pro en sus productos (Bard Ultra, Search AI Mode, Codey, etc.), lo cual confirma su disponibilidad una vez se cumplen los requisitos.

Guía para adaptar la extensión LIA a Gemini 3 (Pro/Flash)

Para actualizar la extensión LIA y lograr compatibilidad conGemini 3 ProyFlash Preview, se deben realizar los siguientes ajustes y verificaciones:

Usar los nombres de modelo correctos:Asegúrate de que en la configuración se utilicen exactamente**"gemini-3-flash-preview"**y**"gemini-3-pro-preview"**(u otro sufijo vigente). Si en alguna parte del código se construye el endpoint manualmente, incluya**.../models/gemini-3-flash-preview**etc. En el snippet de LIA**config.ts**ya aparece así[[18]](https://github.com/fernandosuarez-04/Lia-Extension/blob/9a2b3e0d19918d59a24474b4fe3c15ce915a08bd/src/config.ts#L5-L12), por lo que el foco es corroborar que la variable correcta se pasa a la llamada. En caso de que el error 404 proviniera de un valor diferente (por ejemplo, un string “gemini-3-pro” codificado en alguna parte), buscar y reemplazar por el correcto.

Actualizar la versión de la API (y SDK):La dependencia**@google/generative-ai**en LIA está en versión 0.24.1[[35]](https://github.com/fernandosuarez-04/Lia-Extension/blob/9a2b3e0d19918d59a24474b4fe3c15ce915a08bd/package.json#L11-L19). Es probable que esta versión se haya lanzado antes de Gemini 3 y por tanto desconozca esos modelos. Sería conveniente actualizar a la versión más reciente disponible (por ejemplo, la librería se renombró a**@google/genai**en 2024/2025). Versiones ≥0.27.0 incluyeron soporte para modelos 2.5, y muy posiblemente 0.3x o 1.x para modelos 3. Una pista: en un caso análogo, se recomendó“actualizar google-generativeai >= 0.4.0”para soportar nuevos modelos[[36]](https://github.com/langgenius/dify/discussions/17263#:~:text=3.%20Update%20google). Revisa el changelog de la librería para confirmar soporte de gemini-3. Tras actualizar, recompile la extensión. Esto probablemente ajustará la forma en que se construyen las URL (posiblemente el SDK más nuevo use ya**v1**endpoints internamente y maneje mejor el streaming).

Preferir el endpoint v1 estable:Si la librería no ofrece una opción directa, puedes forzar el uso de v1 construyendo manualmente la URL de API. Sin embargo, dado que Google mantiene backward compatibility, no es estrictamente necesario si v1beta funciona. Aun así, se aconseja moverse a v1 para evitar deprecaciones. Verifica en la documentación de**GoogleGenerativeAI**si hay parámetro para la versión. Si no, una opción es usar directamente el cliente de**@google/genai**(la nueva librería) dondepor defecto ya usa v1. Un ejemplo desde la doc:**genai.Client()**seguido de**client.models.generate_content(model="gemini-3-flash-preview", ...)**[[37]](https://ai.google.dev/gemini-api/docs#:~:text=from%20google%20import%20genai)debería funcionar, y por debajo llama av1(dado que en ejemplos cURL de blogs comunitarios se ve**v1/models/gemini-3-flash:generateContent**[[38]](https://devops-geek.net/devops-lab/gemini-3-flash-lightning-fast-ai-that-actually-respects-your-hardware/#:~:text=geek,)funcionando). En resumen:no usar rutas retiradas(como v1alpha) para estos modelos; centrarse en v1beta/v1.

Implementar correctamente el streaming:La extensión ya usa**sendMessageStream**que debería emitir fragmentos de respuesta. Confirma que esto internamente está haciendo la llamada SSE correcta. Si tras los cambios persiste un error en**streamGenerateContent**, una solución alternativa es realizar la llamada streaming manualmente. Esto implicaría utilizar fetch/XHR con**Accept: text/event-stream**(o**alt=sse**) al endpoint**...:streamGenerateContent**. No obstante, antes de llegar a eso, prueba la vía normal con la librería actualizada. Google indica que**streamGenerateContent**“recibe la misma request que generateContent, pero streamea trozos de la respuesta a medida que se generan”[[39]](https://ai.google.dev/api#:~:text=,you%20display%20partial%20results%20immediately), por lo que no requiere cuerpo diferente. En Node, el SDK puede proveer un método o un campo en la respuesta (p.ej.**result.stream**en el código LIA[[40]](https://github.com/fernandosuarez-04/Lia-Extension/blob/9a2b3e0d19918d59a24474b4fe3c15ce915a08bd/src/services/gemini.ts#L96-L104)sugiere que después de**sendMessageStream**,**result.stream**es unReadableStreamde chunks). Asegúrate de consumir ese stream correctamente. Si 0.24 presentara bug con stream (posible, dado el reddit donde preguntan por disponibilidad de 3 Flash en**google.genai**SDK[[41]](https://www.reddit.com/r/Bard/comments/1popdps/gemini3flashpreview_is_the_model_id_i_tried_in_on/#:~:text=%E2%80%A2%20%2027d%20ago%20,%E2%80%A2%20Edited%2027d%20ago)), la actualización debería resolverlo.

Headers y cuerpo de solicitud:No parece que haya cambios de formato de request al pasar a Gemini 3; la estructura**contents**con**parts**es igual. Solo debes incluir la API key en la cabecera (ya lo hace el SDK). No se requieren headers adicionales específicos para Gemini 3. Sí se debe tener en cuenta el tamaño de contexto:Gemini 3maneja hasta 1 millón de tokens de entrada[[5]](https://ai.google.dev/gemini-api/docs/gemini-3#:~:text=2,to%2064k%20tokens%20of%20output), pero esto no afecta la llamada en sí, solo que puedes enviar más texto. Un punto a revisar es si la extensión está usandopaquetes SSE nativos del navegador: dado que LIA es una extensión Chrome, paraSSEpodrías usar**EventSource**. Quizá la librería ya gestiona esto vía fetch, pero en entornos web es posible que se necesite usar**EventSource**API de JS para recibir streams. Si**sendMessageStream**no funciona en la extensión (tal vez pensado para Node), una alternativa es implementar una pequeña función que haga:

**const evtSource = new EventSource("https://generativelanguage.googleapis.com/v1beta/models/gemini-3-flash-preview:streamGenerateContent?key=API_KEY", { method: 'POST', body: JSON... });**

Sin embargo,Chrome extensionstienen políticas de CORS y puede complicarse. Idealmente confiar en la librería. Con la actualización a la versión oficial (ahora llamada Google GenAI JS SDK), debería funcionar en navegador ya que Google AI dev tenía esta use-case en mente.

Manejo de errores y fallback:Incorpora lógica defallbackrobusta. LIA ya define un**fallbackModel**(Pro)[[42]](https://github.com/fernandosuarez-04/Lia-Extension/blob/9a2b3e0d19918d59a24474b4fe3c15ce915a08bd/src/services/gemini.ts#L41-L49)en caso de que el modelo principal (Flash) falle. Asegúrate de usarlo: es decir, si la promesa de**sendMessageStream**rechaza con 404 al usar Flash, atrápalo y reintenta con**fallbackModel.startChat(...)**. Podrías implementar esto dentro de**startChatSession**o en la llamada a sendMessage. Un pseudocódigo:

**try {**
result = await chatSession.sendMessageStream(prompt);
} catch(e) {
console.error("Primary model failed, trying fallback:", e);
chatSession = fallbackModel.startChat(...);
result = await chatSession.sendMessageStream(prompt);
}

Así, si Flash no está disponible por la razón que sea, Pro tomará el relevo (suponiendo que el usuario tenga Pro). También podrías hacer al revés: detectar mediante ListModels si flash no aparece y cambiar PRIMARY a pro dinámicamente.

Verificar permisos de API Key:Si pese a todoGemini 3 Prosigue dando 404, es probable que la API key no tenga acceso. En ese caso, documenta claramente al usuario (o en la UI) quePro requiere activación Ultra o plan de pago. Una buena práctica es capturar el mensaje de error y si contiene**"code":404**y**"message":"Requested entity was not found"**, mostrar algo como “El modelo no está disponible. ¿Tiene acceso Ultra/pago habilitado?”. Por otro lado,Flashal tener free tier debería funcionar; si tampoco, sugerir verificar en AI Studio la activación.

Conservar métodos anteriores como respaldo:No elimines inmediatamente la compatibilidad con Gemini 2.5 en LIA. Podría darse el caso que algún usuario no tenga todavía acceso a 3, en cuyo caso podrías mantener 2.5 comofallbackfinal. Por ejemplo, tu**MODELS.LIVE**=**gemini-2.0-flash-exp**aún puede ser útil en caso extremo. Pero esto es opcional y según la estrategia de tu extensión.

Siguiendo estos pasos, la extensión quedará preparada para utilizarGemini 3. En resumen:actualizar nombres de modelos, actualizar SDK, usar endpoints correctos (preferiblemente v1), y manejar errores de acceso con fallbackson las claves para la adaptación exitosa.

Conclusiones y Recomendaciones

Adaptar la extensión LIA para soportarGemini 3 ProyGemini 3 Flash Previewes factible con cambios relativamente menores, centrados en el uso correcto de la API más que en reescribir la lógica de negocio. Se confirmó que ambos modelossí están disponibles en la API de Google AI para desarrolladores(actualmente vía v1beta, con soporte en v1 estable también) siempre que se use elidentificador exacto del modelo con sufijo “-preview”[[1]](https://ai.google.dev/gemini-api/docs/gemini-3#:~:text=REST)y que laAPI key tenga los permisos necesarios(Ultra/pago para Pro, libre para Flash). Igualmente, los dos modelos soportan tanto la generación estándar como elstreamingde contenido – las llamadas**generateContent**entregan la respuesta completa y**streamGenerateContent**permite recibirla progresivamente[[2]](https://ai.google.dev/api#:~:text=,time%20conversational%20use%20cases). El error 404 encontrado no implica queGemini 3“no soporte” estos métodos, sino problemas de acceso o endpoint incorrecto[[6]](https://www.reddit.com/r/Bard/comments/1popdps/gemini3flashpreview_is_the_model_id_i_tried_in_on/#:~:text=ClientError%3A%20got%20status%3A%20404%20Not,NOT_FOUND).

En cuanto a las diferencias con la generación anterior,Gemini 3unifica y simplifica la interacción (usando siempre**generateContent**con roles), a la vez que introduce parámetros nuevos para controlar la profundidad de razonamiento y la resolución multimodal. No hay cambios drásticos en la estructura de la petición JSON, por lo que la transición desde Gemini 2.5 es directa, aparte de actualizar nombres y quitar ajustes obsoletos (p. ej., evitarthinking_budget, usarthinking_level). Algunostools(Maps, Computer Use) aún no están en 3, lo cual se debe tener en cuenta para seguir usando modelos 2.x en esas funciones especiales de LIA[[3]](https://ai.google.dev/gemini-api/docs/gemini-3#:~:text=1.5%20.%20,calling%20is%20not%20yet%20supported).

Recomendación de modelo por defecto:Dado el panorama actual de disponibilidad, se aconseja usarGemini 3 Flashcomo modelo principal por defecto en la extensión. Esto por varias razones: (a)Flashofrece rendimiento casi de nivel Pro en muchas tareas[[10]](https://ai.google.dev/gemini-api/docs/gemini-3#:~:text=Gemini%203%20Pro%2C%20the%20first,and%20advanced%20reasoning%20across%20modalities)pero con menor costo y latencia, ideal para un asistente interactivo; (b) tieneacceso amplio, incluyendo un nivel gratuito en la API[[5]](https://ai.google.dev/gemini-api/docs/gemini-3#:~:text=2,to%2064k%20tokens%20of%20output), lo que significa que todos los usuarios desarrolladores pueden aprovecharlo inmediatamente; (c) reduce la dependencia de la suscripción Ultra, haciendo la extensión utilizable por una audiencia mayor. Por su parte,Gemini 3 Propuede configurarse comoopción secundaria o de respaldo: para aquellos usuarios que sí cuenten con credenciales Ultra o requieran el máximo desempeño en tareas complejas, Pro puede usarse cuando Flash no alcance o si el usuario lo selecciona explícitamente. En la configuración actual de LIA, esto ya se contempla con**PRIMARY**= Flash y**FALLBACK**= Pro[[18]](https://github.com/fernandosuarez-04/Lia-Extension/blob/9a2b3e0d19918d59a24474b4fe3c15ce915a08bd/src/config.ts#L5-L12), alineándose con esta recomendación. Solo se debe asegurar que la conmutación ocurre sin problemas en caso de error, tal como mencionamos.

En conclusión, para lograr que LIA funcione conGemini 3se debencorregir los endpoints/modelos llamados y gestionar el acceso adecuado, más que cambiar la lógica de generación. Revisada la documentación oficial y experiencias de la comunidad, no hay indicios de un bug inherente en la API para estos nuevos modelos, sino consideraciones de lanzamiento controlado. Aplicando las modificaciones descritas, LIA podrá aprovechar el poder deGemini 3 ProyFlashplenamente: ofreciendo respuestas más inteligentes y multimodales, con streaming fluido, y seleccionando automáticamente el mejor modelo disponible según la disponibilidad de la API key del usuario. Esto garantizará compatibilidad hacia adelante y una mejor experiencia para los usuarios de la extensión.

Fuentes:La información anterior se fundamenta en la documentación oficial de Google AI Developer sobre Gemini 3[[1]](https://ai.google.dev/gemini-api/docs/gemini-3#:~:text=REST)[[7]](https://ai.google.dev/gemini-api/docs/gemini-3#:~:text=Nano%20Banana%20Pro%20,quality%20image%20generation%20model%20yet), discusiones técnicas en foros de desarrolladores de Google y GitHub (que reportan errores 404 y sus soluciones)[[6]](https://www.reddit.com/r/Bard/comments/1popdps/gemini3flashpreview_is_the_model_id_i_tried_in_on/#:~:text=ClientError%3A%20got%20status%3A%20404%20Not,NOT_FOUND)[[8]](https://github.com/langgenius/dify/discussions/17263#:~:text=4), así como guías de migración de modelos[[43]](https://ai.google.dev/gemini-api/docs/gemini-3#:~:text=Gemini%203%20is%20our%20most,When%20migrating%2C%20consider%20the%20following)[[5]](https://ai.google.dev/gemini-api/docs/gemini-3#:~:text=2,to%2064k%20tokens%20of%20output). Estas referencias confirman la disponibilidad de los modelos en preview, sus requisitos de acceso, y las mejores prácticas para integrarlos correctamente en aplicaciones de terceros. En particular, laGuía de Desarrollador de Gemini 3destaca ejemplos de llamadas a la API con los modelos preview[[1]](https://ai.google.dev/gemini-api/docs/gemini-3#:~:text=REST)y detalla las nuevas capacidades y limitaciones relevantes[[3]](https://ai.google.dev/gemini-api/docs/gemini-3#:~:text=1.5%20.%20,calling%20is%20not%20yet%20supported)[[27]](https://ai.google.dev/gemini-api/docs/gemini-3#:~:text=7,Use%20are%20currently%20not%20supported). Adicionalmente, reportes comunitarios en Reddit y GitHub han sido útiles para identificar problemas iniciales de disponibilidad deGemini 3 Flashy cómo solucionarlos[[6]](https://www.reddit.com/r/Bard/comments/1popdps/gemini3flashpreview_is_the_model_id_i_tried_in_on/#:~:text=ClientError%3A%20got%20status%3A%20404%20Not,NOT_FOUND)[[12]](https://www.reddit.com/r/Bard/comments/1popdps/gemini3flashpreview_is_the_model_id_i_tried_in_on/#:~:text=%E2%80%A2%20%2028d%20ago). Con base en todo ello, las recomendaciones proporcionadas abordan los objetivos planteados y ofrecen un camino claro para adaptar la extensión LIA a la nueva generación de modelos Gemini.

[[1]](https://ai.google.dev/gemini-api/docs/gemini-3#:~:text=REST)[[3]](https://ai.google.dev/gemini-api/docs/gemini-3#:~:text=1.5%20.%20,calling%20is%20not%20yet%20supported)[[5]](https://ai.google.dev/gemini-api/docs/gemini-3#:~:text=2,to%2064k%20tokens%20of%20output)[[7]](https://ai.google.dev/gemini-api/docs/gemini-3#:~:text=Nano%20Banana%20Pro%20,quality%20image%20generation%20model%20yet)[[10]](https://ai.google.dev/gemini-api/docs/gemini-3#:~:text=Gemini%203%20Pro%2C%20the%20first,and%20advanced%20reasoning%20across%20modalities)[[17]](https://ai.google.dev/gemini-api/docs/gemini-3#:~:text=curl%20%22https%3A%2F%2Fgenerativelanguage.googleapis.com%2Fv1beta%2Fmodels%2Fgemini,%5B)[[21]](https://ai.google.dev/gemini-api/docs/gemini-3#:~:text=Thinking%20level)[[22]](https://ai.google.dev/gemini-api/docs/gemini-3#:~:text=response%20%3D%20client.models.generate_content%28%20model%3D%22gemini,%29%2C)[[23]](https://ai.google.dev/gemini-api/docs/gemini-3#:~:text=carefully%20reasoned)[[24]](https://ai.google.dev/gemini-api/docs/gemini-3#:~:text=Media%20resolution)[[25]](https://ai.google.dev/gemini-api/docs/gemini-3#:~:text=,document%20parsing%2C%20test%20the%20new)[[27]](https://ai.google.dev/gemini-api/docs/gemini-3#:~:text=7,Use%20are%20currently%20not%20supported)[[43]](https://ai.google.dev/gemini-api/docs/gemini-3#:~:text=Gemini%203%20is%20our%20most,When%20migrating%2C%20consider%20the%20following)Gemini 3 Developer Guide | Gemini API | Google AI for Developers

[https://ai.google.dev/gemini-api/docs/gemini-3](https://ai.google.dev/gemini-api/docs/gemini-3)

[[2]](https://ai.google.dev/api#:~:text=,time%20conversational%20use%20cases)[[14]](https://ai.google.dev/api#:~:text=The%20Gemini%20API%20is%20organized,around%20the%20following%20major%20endpoints)[[19]](https://ai.google.dev/api#:~:text=The%20following%20shows%20a%20typical,request%20body)[[20]](https://ai.google.dev/api#:~:text=,Part%20objects%20goes%20here)[[39]](https://ai.google.dev/api#:~:text=,you%20display%20partial%20results%20immediately)Gemini API reference | Google AI for Developers

[https://ai.google.dev/api](https://ai.google.dev/api)

[[4]](https://github.com/google-gemini/gemini-cli/discussions/13280#:~:text=Gemini%203%20Pro%20is%20available,now%20in%20Gemini%20CLI%20for)[[9]](https://github.com/google-gemini/gemini-cli/discussions/13280#:~:text=%E2%8F%B3Waitlist)️ Gemini 3 Pro is now available in Gemini CLI! · google-gemini gemini-cli · Discussion #13280 · GitHub

[https://github.com/google-gemini/gemini-cli/discussions/13280](https://github.com/google-gemini/gemini-cli/discussions/13280)

[[6]](https://www.reddit.com/r/Bard/comments/1popdps/gemini3flashpreview_is_the_model_id_i_tried_in_on/#:~:text=ClientError%3A%20got%20status%3A%20404%20Not,NOT_FOUND)[[11]](https://www.reddit.com/r/Bard/comments/1popdps/gemini3flashpreview_is_the_model_id_i_tried_in_on/#:~:text=ClientError%3A%20got%20status%3A%20404%20Not,NOT_FOUND)[[12]](https://www.reddit.com/r/Bard/comments/1popdps/gemini3flashpreview_is_the_model_id_i_tried_in_on/#:~:text=%E2%80%A2%20%2028d%20ago)[[34]](https://www.reddit.com/r/Bard/comments/1popdps/gemini3flashpreview_is_the_model_id_i_tried_in_on/#:~:text=%E2%80%A2%20%2028d%20ago)[[41]](https://www.reddit.com/r/Bard/comments/1popdps/gemini3flashpreview_is_the_model_id_i_tried_in_on/#:~:text=%E2%80%A2%20%2027d%20ago%20,%E2%80%A2%20Edited%2027d%20ago)gemini-3-flash-preview is the model id. I tried in on VertexAI. Its amazing! : r/Bard

[https://www.reddit.com/r/Bard/comments/1popdps/gemini3flashpreview_is_the_model_id_i_tried_in_on/](https://www.reddit.com/r/Bard/comments/1popdps/gemini3flashpreview_is_the_model_id_i_tried_in_on/)

[[8]](https://github.com/langgenius/dify/discussions/17263#:~:text=4)[[13]](https://github.com/langgenius/dify/discussions/17263#:~:text=Ensure%20your%20Gemini%20API%20key,Check%20available%20models%20with%3A%20bash)[[36]](https://github.com/langgenius/dify/discussions/17263#:~:text=3.%20Update%20google)404 models/gemini-pro is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods. · langgenius dify · Discussion #17263 · GitHub

[https://github.com/langgenius/dify/discussions/17263](https://github.com/langgenius/dify/discussions/17263)

[[15]](https://github.com/fernandosuarez-04/Lia-Extension/blob/9a2b3e0d19918d59a24474b4fe3c15ce915a08bd/src/config.ts#L14-L16)[[18]](https://github.com/fernandosuarez-04/Lia-Extension/blob/9a2b3e0d19918d59a24474b4fe3c15ce915a08bd/src/config.ts#L5-L12)[[26]](https://github.com/fernandosuarez-04/Lia-Extension/blob/9a2b3e0d19918d59a24474b4fe3c15ce915a08bd/src/config.ts#L6-L12)config.ts

[https://github.com/fernandosuarez-04/Lia-Extension/blob/9a2b3e0d19918d59a24474b4fe3c15ce915a08bd/src/config.ts](https://github.com/fernandosuarez-04/Lia-Extension/blob/9a2b3e0d19918d59a24474b4fe3c15ce915a08bd/src/config.ts)

[[16]](https://ai.google.dev/gemini-api/docs/text-generation#:~:text=...%20streamGenerateContent%3Falt%3Dsse%22%20%5C%20,d%20%27%7B%20%22contents)Text generation | Gemini API | Google AI for Developers

[https://ai.google.dev/gemini-api/docs/text-generation](https://ai.google.dev/gemini-api/docs/text-generation)

[[28]](https://github.com/fernandosuarez-04/Lia-Extension/blob/9a2b3e0d19918d59a24474b4fe3c15ce915a08bd/src/services/gemini.ts#L26-L34)[[29]](https://github.com/fernandosuarez-04/Lia-Extension/blob/9a2b3e0d19918d59a24474b4fe3c15ce915a08bd/src/services/gemini.ts#L130-L138)[[40]](https://github.com/fernandosuarez-04/Lia-Extension/blob/9a2b3e0d19918d59a24474b4fe3c15ce915a08bd/src/services/gemini.ts#L96-L104)[[42]](https://github.com/fernandosuarez-04/Lia-Extension/blob/9a2b3e0d19918d59a24474b4fe3c15ce915a08bd/src/services/gemini.ts#L41-L49)gemini.ts

[https://github.com/fernandosuarez-04/Lia-Extension/blob/9a2b3e0d19918d59a24474b4fe3c15ce915a08bd/src/services/gemini.ts](https://github.com/fernandosuarez-04/Lia-Extension/blob/9a2b3e0d19918d59a24474b4fe3c15ce915a08bd/src/services/gemini.ts)

[[30]](https://blog.google/innovation-and-ai/technology/developers-tools/gdp-premium-ai-pro-ultra/#:~:text=New%20developer%20tools%20for%20Google,Pro%20and%20Google%20AI%20Ultra)New developer tools for Google AI Pro and Ultra subscribers

[https://blog.google/innovation-and-ai/technology/developers-tools/gdp-premium-ai-pro-ultra/](https://blog.google/innovation-and-ai/technology/developers-tools/gdp-premium-ai-pro-ultra/)

[[31]](https://github.com/google-gemini/gemini-cli/issues/13284#:~:text=Fix%20Gemini%203%20,the%20waitlist%21%20thanks%20for)Fix Gemini 3 - 404 Requested entity was not found #13284 - GitHub

[https://github.com/google-gemini/gemini-cli/issues/13284](https://github.com/google-gemini/gemini-cli/issues/13284)

[[32]](https://discuss.ai.google.dev/t/gemini-3-error-404-not-found-with-videos-without-an-audio-stream-and-media-resolution-not-set-to-high/113805#:~:text=Gemini%203%20error%20404%20NOT_FOUND,fails%20unless%20MEDIA_RESOLUTION_HIGH%20is%20set)Gemini 3 error 404 NOT_FOUND with videos without an audio ...

[https://discuss.ai.google.dev/t/gemini-3-error-404-not-found-with-videos-without-an-audio-stream-and-media-resolution-not-set-to-high/113805](https://discuss.ai.google.dev/t/gemini-3-error-404-not-found-with-videos-without-an-audio-stream-and-media-resolution-not-set-to-high/113805)

[[33]](https://discuss.ai.google.dev/t/generatecontentstream-throwing-error-for-gemini-tuned-model/39169#:~:text=generateContentStream%20throwing%20error%20for%20Gemini,issue%20only%20for%20the)generateContentStream throwing error for Gemini Tuned Model

[https://discuss.ai.google.dev/t/generatecontentstream-throwing-error-for-gemini-tuned-model/39169](https://discuss.ai.google.dev/t/generatecontentstream-throwing-error-for-gemini-tuned-model/39169)

[[35]](https://github.com/fernandosuarez-04/Lia-Extension/blob/9a2b3e0d19918d59a24474b4fe3c15ce915a08bd/package.json#L11-L19)package.json

[https://github.com/fernandosuarez-04/Lia-Extension/blob/9a2b3e0d19918d59a24474b4fe3c15ce915a08bd/package.json](https://github.com/fernandosuarez-04/Lia-Extension/blob/9a2b3e0d19918d59a24474b4fe3c15ce915a08bd/package.json)

[[37]](https://ai.google.dev/gemini-api/docs#:~:text=from%20google%20import%20genai)Gemini API | Google AI for Developers

[https://ai.google.dev/gemini-api/docs](https://ai.google.dev/gemini-api/docs)

[[38]](https://devops-geek.net/devops-lab/gemini-3-flash-lightning-fast-ai-that-actually-respects-your-hardware/#:~:text=geek,)Gemini 3 Flash: Lightning-Fast AI That Actually Respects Your ...

[https://devops-geek.net/devops-lab/gemini-3-flash-lightning-fast-ai-that-actually-respects-your-hardware/](https://devops-geek.net/devops-lab/gemini-3-flash-lightning-fast-ai-that-actually-respects-your-hardware/)
