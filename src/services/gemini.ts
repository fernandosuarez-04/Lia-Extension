
import { GoogleGenerativeAI } from "@google/generative-ai";
import { GOOGLE_API_KEY, MODELS } from "../config";
import {
  buildComputerUsePrompt,
  buildPrimaryChatPrompt,
  PRIMARY_CHAT_PROMPT,
  PROMPT_OPTIMIZER,
  AUDIO_TRANSCRIPTION_PROMPT,
  getImageGenerationPrompt,
  needsComputerUse
} from "../prompts";
import { getApiKeyWithCache } from "./api-keys";

// Lazy initialization for GoogleGenerativeAI
// This allows us to fetch the API key from database when needed
let genAI: GoogleGenerativeAI | null = null;
let currentApiKey: string | null = null;

/**
 * Gets or creates a GoogleGenerativeAI instance with the current API key
 * Fetches from database (with cache) if available, falls back to env variable
 */
async function getGenAI(): Promise<GoogleGenerativeAI> {
  try {
    // Try to get API key from database (user's key or system default)
    const dbApiKey = await getApiKeyWithCache('google');

    if (dbApiKey) {
      // If we have a new key or no instance yet, create/recreate
      if (!genAI || currentApiKey !== dbApiKey) {
        genAI = new GoogleGenerativeAI(dbApiKey);
        currentApiKey = dbApiKey;
        console.log('üîë Using API key from database');
      }
      return genAI;
    }
  } catch (error) {
    console.warn('Could not fetch API key from database, using fallback:', error);
  }

  // Fallback to environment variable
  if (!genAI || currentApiKey !== GOOGLE_API_KEY) {
    if (!GOOGLE_API_KEY) {
      throw new Error('No API key available. Please configure your Google API key in settings.');
    }
    genAI = new GoogleGenerativeAI(GOOGLE_API_KEY);
    currentApiKey = GOOGLE_API_KEY;
    console.log('üîë Using API key from environment');
  }

  return genAI;
}

// Gemini 3 no soporta googleSearch + functionDeclarations juntos (error 400)
// Solo Google Search como tool para los modelos primario y deep research
const searchTools: any[] = [
  { googleSearch: {} },
];

// Model getter functions (lazy initialization)
async function getPrimaryModel() {
  const ai = await getGenAI();
  return ai.getGenerativeModel({
    model: MODELS.PRIMARY,
    tools: searchTools,
  });
}

async function getComputerUseModel() {
  const ai = await getGenAI();
  return ai.getGenerativeModel({
    model: MODELS.COMPUTER_USE,
  });
}

async function getImageGenerationModel() {
  const ai = await getGenAI();
  return ai.getGenerativeModel({
    model: MODELS.IMAGE_GENERATION,
  });
}

async function getProModel() {
  const ai = await getGenAI();
  return ai.getGenerativeModel({
    model: (MODELS as any).PRO || "gemini-2.5-pro",
  });
}

let chatSession: any = null;

// Deep Research Function - Uses official @google/genai SDK for Interactions API
// Documentation: https://ai.google.dev/gemini-api/docs/deep-research
// Deep Research analyzes up to 100+ sources and takes 2-15 minutes to complete
export const runDeepResearch = async (prompt: string) => {
  try {
    console.log("üî¨ Starting Deep Research with prompt:", prompt);
    console.log("üìö Agent:", MODELS.DEEP_RESEARCH);

    // Get API key from database or fallback to env
    let apiKey = await getApiKeyWithCache('google');
    if (!apiKey) {
      apiKey = GOOGLE_API_KEY;
    }
    if (!apiKey) {
      throw new Error('No API key available for Deep Research');
    }

    // Import the new Google GenAI SDK (required for Interactions API)
    const { GoogleGenAI } = await import('@google/genai');
    const client = new GoogleGenAI({ apiKey });

    // Step 1: Create the research interaction
    console.log("üì§ Creating interaction...");
    const interaction = await client.interactions.create({
      agent: MODELS.DEEP_RESEARCH as 'deep-research-pro-preview-12-2025',
      input: prompt,
      background: true // Required for async execution
    });

    // Get interaction ID - can be in 'name' or 'id' field
    const interactionId = (interaction as any).name || (interaction as any).id;
    if (!interactionId) {
      console.log("Full interaction response:", JSON.stringify(interaction, null, 2));
      throw new Error("No interaction ID received from API");
    }
    console.log("‚úÖ Deep Research interaction created:", interactionId);

    // Step 2: Poll for results - Deep Research takes 2-15 minutes
    async function* pollForResults(): AsyncGenerator<{ text: () => string }> {
      let isComplete = false;
      let pollCount = 0;
      const POLL_INTERVAL_MS = 15000; // 15 seconds between polls
      const MAX_POLLS = 60; // 60 polls * 15 seconds = 15 minutes max

      // Initial status message
      yield { text: () => "# üî¨ Investigaci√≥n Profunda Iniciada\n\n" };
      yield { text: () => "Lia est√° analizando m√∫ltiples fuentes web para darte una respuesta completa y fundamentada.\n\n" };
      yield { text: () => "‚è±Ô∏è **Tiempo estimado:** 2-10 minutos\n\n---\n\n" };

      while (!isComplete && pollCount < MAX_POLLS) {
        pollCount++;

        // Wait before polling
        await new Promise(resolve => setTimeout(resolve, POLL_INTERVAL_MS));

        const elapsedMinutes = Math.floor((pollCount * 15) / 60);
        const elapsedSeconds = (pollCount * 15) % 60;

        try {
          // Poll using the SDK - get(id, params)
          const result = await client.interactions.get(interactionId) as any;

          const status = result.status || (result.done ? "COMPLETED" : "IN_PROGRESS");
          console.log(`üîÑ Poll #${pollCount} (${elapsedMinutes}m ${elapsedSeconds}s): Status = ${status}`);

          // Show progress
          yield { text: () => `üîç **Investigando...** (${elapsedMinutes}m ${elapsedSeconds}s)\n` };

          // Check for completion
          if (status === "COMPLETED" || status === "completed" || result.done === true) {
            isComplete = true;
            console.log("‚úÖ Research completed!");
            console.log("Full result:", JSON.stringify(result, null, 2).substring(0, 1000));

            // Extract final response - try multiple formats
            let finalText = "";

            // Format 1: outputs array (Interactions API standard)
            if (result.outputs && Array.isArray(result.outputs)) {
              const lastOutput = result.outputs[result.outputs.length - 1];
              if (lastOutput?.text) {
                finalText = lastOutput.text;
              } else if (typeof lastOutput === 'string') {
                finalText = lastOutput;
              }
            }

            // Format 2: modelContent.parts
            if (!finalText && result.modelContent?.parts) {
              for (const part of result.modelContent.parts) {
                if (part.text) finalText += part.text;
              }
            }

            // Format 3: content.parts
            if (!finalText && result.content?.parts) {
              for (const part of result.content.parts) {
                if (part.text) finalText += part.text;
              }
            }

            // Format 4: Direct text field
            if (!finalText && result.text) {
              finalText = result.text;
            }

            if (finalText) {
              yield { text: () => "\n\n---\n\n# üìã Resultado de la Investigaci√≥n\n\n" };
              yield { text: () => finalText };
            } else {
              yield { text: () => "\n\n‚ö†Ô∏è La investigaci√≥n termin√≥ pero no se obtuvo contenido.\n" };
              console.log("Full response:", JSON.stringify(result, null, 2));
            }
          }

          // Check for failure
          if (status === "FAILED" || status === "failed" || status === "CANCELLED" || status === "cancelled") {
            isComplete = true;
            const errorMsg = result.error?.message || result.error || "Error desconocido";
            yield { text: () => `\n\n‚ùå **La investigaci√≥n fall√≥:** ${errorMsg}\n` };
          }

        } catch (pollError: any) {
          console.error(`‚ùå Poll #${pollCount} error:`, pollError);
          // Continue polling unless it's a fatal error
          if (pollError.message?.includes('not found') || pollError.message?.includes('404')) {
            yield { text: () => `\n\n‚ùå **Error:** La investigaci√≥n no se encontr√≥.\n` };
            isComplete = true;
          }
        }
      }

      if (!isComplete) {
        yield { text: () => "\n\n‚ö†Ô∏è La investigaci√≥n est√° tomando m√°s de 15 minutos. Por favor intenta con una consulta m√°s espec√≠fica.\n" };
      }
    }

    return {
      stream: pollForResults(),
      getGroundingMetadata: async () => null
    };

  } catch (error: any) {
    console.error("‚ùå Deep Research error:", error);

    // If SDK doesn't support interactions, fall back to enhanced search
    if (error.message?.includes('interactions') || error.message?.includes('not a function') || error.message?.includes('not supported')) {
      console.log("‚ö†Ô∏è Interactions API not available, falling back to enhanced search...");
      return runEnhancedResearch(prompt);
    }

    throw error;
  }
};

// Fallback: Enhanced Research using regular Gemini with Google Search grounding
async function runEnhancedResearch(prompt: string) {
  console.log("üîÑ Using enhanced search fallback...");

  const researchPrompt = `Realiza una investigaci√≥n exhaustiva sobre el siguiente tema.
Busca informaci√≥n en m√∫ltiples fuentes web y proporciona:

1. **Resumen Ejecutivo** - Puntos clave en 2-3 p√°rrafos
2. **An√°lisis Detallado** - Informaci√≥n profunda del tema
3. **Datos y Estad√≠sticas** - N√∫meros y hechos relevantes
4. **Diferentes Perspectivas** - Puntos de vista variados si aplica
5. **Conclusiones** - S√≠ntesis final

TEMA A INVESTIGAR:
${prompt}

Responde de forma estructurada y completa, citando fuentes cuando sea posible.`;

  const localSearchTools: any[] = [{ googleSearch: {} }];
  const ai = await getGenAI();
  const researchModel = ai.getGenerativeModel({
    model: MODELS.FALLBACK,
    tools: localSearchTools,
  });

  const result = await researchModel.generateContentStream(researchPrompt);

  return {
    stream: (async function* () {
      yield { text: () => "# üîç Investigaci√≥n en Progreso\n\n" };
      yield { text: () => "_Usando b√∫squeda avanzada con Google Search..._\n\n---\n\n" };

      for await (const chunk of result.stream) {
        const text = chunk.text();
        if (text) {
          yield { text: () => text };
        }
      }
    })(),
    getGroundingMetadata: async () => {
      try {
        const response = await result.response;
        return response.candidates?.[0]?.groundingMetadata || null;
      } catch {
        return null;
      }
    }
  };
}



// Image Generation Function
export const generateImage = async (prompt: string): Promise<{ text: string; imageData?: string }> => {
  try {
    console.log("Generating image with prompt:", prompt);

    const enhancedPrompt = getImageGenerationPrompt(prompt);
    const imageModel = await getImageGenerationModel();

    // Use generateContent with responseModalities in the request
    const result = await (imageModel as any).generateContent({
      contents: [{ role: "user", parts: [{ text: enhancedPrompt }] }],
      generationConfig: {
        responseModalities: ["TEXT", "IMAGE"],
      },
    });
    
    const response = result.response;
    const candidate = response.candidates?.[0];
    
    let textResponse = '';
    let imageData: string | undefined;
    
    if (candidate?.content?.parts) {
      for (const part of candidate.content.parts) {
        if (part.text) {
          textResponse += part.text;
        }
        if (part.inlineData) {
          // Image data is base64 encoded
          const mimeType = part.inlineData.mimeType || 'image/png';
          imageData = `data:${mimeType};base64,${part.inlineData.data}`;
        }
      }
    }
    
    return { 
      text: textResponse || '¬°Aqu√≠ est√° tu imagen generada!', 
      imageData 
    };
  } catch (error) {
    console.error("Image generation error:", error);
    throw error;
  }
};

export const startChatSession = async (history: any[] = []) => {
  const model = await getPrimaryModel();
  chatSession = model.startChat({
    history: history,
    generationConfig: {
      maxOutputTokens: 16384,
    },
  });
  return chatSession;
};

// Thinking config types
// Gemini 3: uses thinkingLevel ("minimal", "low", "medium", "high")
// Gemini 2.5: uses thinkingBudget (0 to 24576 tokens, or -1 for dynamic)
export interface ThinkingConfig {
  mode: 'off' | 'minimal' | 'low' | 'medium' | 'high';
  type: 'level' | 'budget'; // Gemini 3 uses 'level', Gemini 2.5 uses 'budget'
}

// Budget values for Gemini 2.5 (0 = off for Flash, 128-24576 range)
const THINKING_BUDGETS: Record<string, number> = {
  off: 0,
  minimal: 0,
  low: 1024,
  medium: 8192,
  high: 24576
};

// ============================================
// DEEP ANALYSIS DETECTION AND BOOST
// ============================================
const DEEP_ANALYSIS_TRIGGERS = [
  'analiza profundamente', 'analiza a fondo', 'an√°lisis profundo', 'an√°lisis detallado',
  'analizar profundamente', 'analizar a fondo', 'an√°lisis exhaustivo', 'analiza completamente',
  'an√°lisis completo', 'profundiza', 'explica a fondo', 'explica en detalle',
  'explicaci√≥n detallada', 'quiero todos los detalles', 'dime todo sobre', 'cu√©ntame todo',
  'an√°lisis extenso', 'deep analysis', 'full analysis', 'dame un an√°lisis completo',
  'analiza la pagina', 'analiza la p√°gina', 'analiza esta pagina', 'analiza esta p√°gina'
];

const needsDeepAnalysis = (message: string): boolean => {
  const lowerMessage = message.toLowerCase();
  return DEEP_ANALYSIS_TRIGGERS.some(trigger => lowerMessage.includes(trigger));
};

// Prompt COMPLETAMENTE SEPARADO para an√°lisis profundo
const DEEP_ANALYSIS_ONLY_PROMPT = `Eres Lia, una analista de contenido. Tu tarea es analizar el CONTENIDO INTELECTUAL de la p√°gina.

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
üö´ PROHIBICIONES ABSOLUTAS - NUNCA HAGAS ESTO:
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

NUNCA menciones ni analices:
- "Elementos de la Interfaz" o "Interfaz de Usuario"
- "Modelo Utilizado" o qu√© versi√≥n de ChatGPT/IA se usa
- "Barra Lateral" o contenido del sidebar
- "Historial de chats" o proyectos listados
- "Campo de texto", "botones", o elementos interactivos
- "Estado del navegador" o "Estado actual de la p√°gina"
- CUALQUIER cosa sobre la UI, DOM, o estructura t√©cnica de la p√°gina

NUNCA crees secciones como:
- "Elementos de la Interfaz"
- "Estructura de la P√°gina" (en sentido t√©cnico/UI)
- "Herramientas Observadas"
- "Modelo en Uso"

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
‚úÖ ANALIZA √öNICAMENTE EL CONTENIDO INTELECTUAL:
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

- Las IDEAS y CONCEPTOS que se discuten
- Las ESTRATEGIAS y METODOLOG√çAS propuestas
- Los ARGUMENTOS y su justificaci√≥n
- Los FRAMEWORKS o modelos conceptuales (como "Alex Hormozi Style", "Ecuaci√≥n de Valor")
- Las PROPUESTAS concretas y recomendaciones
- Los BENEFICIOS y resultados esperados
- Los P√öBLICOS OBJETIVO mencionados en el contenido
- Las ACCIONES sugeridas dentro de la discusi√≥n

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

REQUISITO: Tu respuesta debe tener M√çNIMO 3000 palabras analizando el CONTENIDO, no la interfaz.

FORMATO OBLIGATORIO - USA EXACTAMENTE ESTA ESTRUCTURA:

## üìã RESUMEN EJECUTIVO
[Escribe M√çNIMO 200 palabras sobre el tema central, prop√≥sito y relevancia del CONTENIDO discutido]

## üéØ TEMA CENTRAL Y CONTEXTO
### Tema Principal
[P√°rrafo de 100+ palabras describiendo el tema central]
### Contexto del Contenido
[D√≥nde se enmarca, es parte de qu√© proyecto o conversaci√≥n]
### Origen y Autor√≠a
[Qui√©n lo cre√≥, cu√°ndo, con qu√© prop√≥sito]
### Prop√≥sito Identificado
[Qu√© intenta lograr el contenido]

## üîç DESGLOSE DETALLADO DEL CONTENIDO
[Crea UNA SUBSECCI√ìN ### para CADA concepto importante. M√≠nimo 8-10 subsecciones]

### [Concepto/Tema 1]
- **Descripci√≥n completa**: [50+ palabras]
- **Rol en el contexto**: [Por qu√© importa]
- **Detalles t√©cnicos**: [Especificaciones si las hay]
- **Implicaciones pr√°cticas**: [Qu√© significa en la pr√°ctica]
- **Conexiones**: [C√≥mo se relaciona con otros elementos]

### [Concepto/Tema 2]
[Repite la misma estructura]

[...contin√∫a con TODOS los conceptos...]

## üèóÔ∏è ARQUITECTURA Y ESTRUCTURA
[M√≠nimo 150 palabras sobre c√≥mo est√° organizado el contenido]

## üí° IDEAS CLAVE Y PROPUESTAS
[Lista numerada con TODAS las ideas. Cada una con 50+ palabras de explicaci√≥n]
1. **[Idea]**: [Explicaci√≥n extensa]
2. ...

## üîß ASPECTOS T√âCNICOS (USA TABLA OBLIGATORIAMENTE)
| Tecnolog√≠a/Herramienta | Descripci√≥n | Funci√≥n/Rol | Beneficio |
|------------------------|-------------|-------------|-----------|
| [Nombre] | [Qu√© es] | [Para qu√© sirve] | [Qu√© aporta] |
| ... | ... | ... | ... |

## üìä DATOS Y EVIDENCIAS
| Dato/M√©trica | Valor | Contexto | Significado |
|--------------|-------|----------|-------------|
| [Nombre del dato] | [Valor] | [D√≥nde se menciona] | [Qu√© implica] |

## üë• STAKEHOLDERS (USA TABLA OBLIGATORIAMENTE)
| Actor/Rol | Descripci√≥n | Inter√©s | Responsabilidad |
|-----------|-------------|---------|-----------------|
| [Nombre/Rol] | [Qui√©n es] | [Qu√© busca] | [Qu√© hace] |
| ... | ... | ... | ... |

## ‚ö° ACCIONES IDENTIFICADAS (USA CHECKLIST)
- [ ] **[Acci√≥n 1]**: [Descripci√≥n detallada y contexto]
- [ ] **[Acci√≥n 2]**: [Descripci√≥n detallada y contexto]
- [ ] **[Acci√≥n 3]**: [Descripci√≥n detallada y contexto]

## üîó CONEXIONES Y RELACIONES
[Muestra las relaciones entre conceptos usando flechas y texto:]
Concepto A ‚Üí Concepto B ‚Üí Resultado
          ‚Üì
     Concepto C

## üí≠ AN√ÅLISIS CR√çTICO
### Fortalezas
[Lista con explicaciones]
### √Åreas de Mejora
[Lista con explicaciones]
### Riesgos
[Lista con explicaciones]

## üìù CONCLUSI√ìN INTEGRAL
[M√çNIMO 250 palabras sintetizando todo, implicaciones y recomendaciones]

---
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
REGLAS CR√çTICAS PARA FORMATO VISUAL:
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
1. TABLAS SON OBLIGATORIAS en: Aspectos T√©cnicos, Stakeholders, Datos
2. USA CHECKLIST (- [ ]) para acciones y tareas
3. USA DIAGRAMAS ASCII para mostrar relaciones y flujos
4. Cada secci√≥n debe tener contenido EXTENSO, no solo bullets
5. NUNCA termines preguntando si quiero m√°s detalles
6. USA negritas **as√≠** para t√©rminos importantes
7. USA c√≥digo \`as√≠\` para t√©rminos t√©cnicos
8. Responde SIEMPRE en espa√±ol
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê`;

export async function sendMessageStream(
  message: string,
  context?: string,
  modelOverrides?: { primary?: string; fallback?: string },
  personalization?: {
    nickname?: string;
    occupation?: string;
    tone?: string;
    about?: string;
    instructions?: string;
  },
  projectContext?: string,
  thinkingConfig?: ThinkingConfig
) {
  // Determine IDs
  const primaryId = modelOverrides?.primary || MODELS.PRIMARY;
  const fallbackId = modelOverrides?.fallback || MODELS.FALLBACK;

  // Detect Computer Use
  const useComputerUse = needsComputerUse(message);

  // Decide active model
  const activeModelId = useComputerUse ? MODELS.COMPUTER_USE : primaryId;

  // Detect if user wants deep analysis
  // Log the message for debugging
  console.log('üîé Message received:', message.substring(0, 200) + '...');
  console.log('üîé Checking for deep analysis triggers...');

  const isDeepAnalysis = needsDeepAnalysis(message);

  console.log('üîé Deep analysis detected:', isDeepAnalysis);

  if (isDeepAnalysis) {
    console.log('üîç DEEP ANALYSIS MODE ACTIVATED - Using DEEP_ANALYSIS_ONLY_PROMPT');
  } else {
    console.log('üìù Normal mode - Using PRIMARY_CHAT_PROMPT');
  }

  // Build Personalized System Instruction
  // IMPORTANT: For deep analysis, put the boost FIRST (LLMs prioritize earlier instructions)
  let systemInstruction: string;

  if (isDeepAnalysis && !useComputerUse) {
    // Deep analysis: use ONLY the deep analysis prompt (it's self-contained)
    // Don't append PRIMARY_CHAT_PROMPT to avoid conflicting instructions
    systemInstruction = DEEP_ANALYSIS_ONLY_PROMPT;
    console.log('‚úÖ System instruction set to: DEEP_ANALYSIS_ONLY_PROMPT');
    console.log('üìè Prompt length:', systemInstruction.length, 'chars');
  } else {
    systemInstruction = PRIMARY_CHAT_PROMPT;
    console.log('üìù System instruction set to: PRIMARY_CHAT_PROMPT');
  }

  if (!useComputerUse && personalization) {
      let personality = "\n\n=== USER PERSONALIZATION SETTINGS ===\n";
      if (personalization.nickname) personality += `User's Name/Nickname: "${personalization.nickname}". Address them by this name occasionally.\n`;
      if (personalization.occupation) personality += `User's Occuption/Role: ${personalization.occupation}. Adapt analogies and complexity to this role.\n`;
      if (personalization.tone) personality += `Response Tone/Style: ${personalization.tone}.\n`;
      if (personalization.about) personality += `More about User: ${personalization.about}\n`;
      if (personalization.instructions) personality += `CUSTOM INSTRUCTIONS (PRIORITY): ${personalization.instructions}\n`;
      personality += "=====================================\n";

      systemInstruction = systemInstruction + personality;
  }

  // Inject Project Context if available
  if (projectContext) {
      systemInstruction += `\n\n=== PROJECT CONTEXT (SHARED KNOWLEDGE) ===\nThe user has grouped this chat in a project folder. Here is relevant context from other chats in the same project:\n\n${projectContext}\n\nUse this information to provide more cohesive and context-aware responses across the project.\n==========================================\n`;
  }

  // Build generation config with thinking settings
  const generationConfig: any = { maxOutputTokens: 16384 };

  // Apply thinking config if provided
  if (thinkingConfig) {
    if (thinkingConfig.type === 'level') {
      // Gemini 3 models use thinkingLevel: "minimal", "low", "medium", "high"
      // "minimal" = fastest, "high" = deepest reasoning
      const validLevels = ['minimal', 'low', 'medium', 'high'];
      const level = validLevels.includes(thinkingConfig.mode) ? thinkingConfig.mode : 'minimal';
      generationConfig.thinkingConfig = {
        thinkingLevel: level
      };
      console.log('Thinking Level:', level);
    } else {
      // Gemini 2.5 models use thinkingBudget (token count: 0-24576, or -1 for dynamic)
      const budget = THINKING_BUDGETS[thinkingConfig.mode] ?? 0;
      // Only set thinkingConfig if budget > 0 (0 means no thinking)
      if (budget > 0) {
        generationConfig.thinkingConfig = {
          thinkingBudget: budget
        };
        console.log('Thinking Budget:', budget);
      } else {
        console.log('Thinking: Off (budget = 0)');
      }
    }
  }

  // Initialize specific model instance dynamically
  const ai = await getGenAI();
  const activeModelInstance = useComputerUse
    ? await getComputerUseModel()
    : ai.getGenerativeModel({
        model: activeModelId,
        tools: searchTools, // Assuming primary/chosen model supports search
        systemInstruction: systemInstruction
      });

  console.log('=== GEMINI SERVICE ===');
  console.log('Model:', activeModelId);
  console.log('Deep Analysis Mode:', isDeepAnalysis);
  console.log('System Instruction Preview:', systemInstruction.substring(0, 100) + '...');
  console.log('Personalization:', !!personalization);
  console.log('Thinking Config:', thinkingConfig);

  // Handle Session Logic - ALWAYS refresh session to apply system prompt updates or model changes
  let currentHistory: any[] = [];
  if (chatSession) {
    try { currentHistory = await chatSession.getHistory(); } catch {}
  }

  // Start fresh session with history to ensure new System Prompt applies
  chatSession = activeModelInstance.startChat({
     history: currentHistory,
     generationConfig
  });

  // Build Prompt
  let prompt = message;
  if (context) {
    prompt = useComputerUse 
      ? buildComputerUsePrompt(context, message) 
      : buildPrimaryChatPrompt(context, message);
  }

  try {
    try {
      const result = await chatSession.sendMessageStream(prompt);
      return {
        stream: result.stream,
        response: result.response,
        getGroundingMetadata: async () => {
             try {
                const r = await result.response;
                return r.candidates?.[0]?.groundingMetadata || null;
             } catch { return null; }
        }
      };
    } catch (primaryError) {
      console.warn(`Primary model (${activeModelId}) failed, trying fallback (${fallbackId})...`, primaryError);

      if (useComputerUse) throw primaryError; // No fallback for computer use

      const history = await chatSession.getHistory();
      const fallbackInstance = ai.getGenerativeModel({
        model: fallbackId,
        systemInstruction: systemInstruction
      });

      const fallbackChat = fallbackInstance.startChat({
        history,
        generationConfig // Apply same generation config (maxOutputTokens, thinking, etc)
      });
      chatSession = fallbackChat; // Update global session

      const result = await fallbackChat.sendMessageStream(prompt);
      return {
        stream: result.stream,
        response: result.response,
        getGroundingMetadata: async () => {
             try {
                const r = await result.response;
                return r.candidates?.[0]?.groundingMetadata || null;
             } catch { return null; }
        }
      };
    }
  } catch (finalError) {
    console.error("All models failed:", finalError);
    throw finalError;
  }
};

// Type for grounding metadata
export interface GroundingSource {
  uri: string;
  title: string;
}

export interface GroundingMetadata {
  searchEntryPoint?: {
    renderedContent: string;
  };
  groundingChunks?: Array<{
    web?: {
      uri: string;
      title: string;
    };
  }>;
  webSearchQueries?: string[];
}

// Types for Maps Grounding
export interface MapPlace {
  placeId?: string;
  name: string;
  location?: { lat: number; lng: number };
  address?: string;
  rating?: number;
  uri?: string;
}

export interface MapsGroundingMetadata {
  groundingChunks?: Array<{
    web?: {
      uri: string;
      title: string;
    };
    retrievedContext?: {
      uri: string;
      title: string;
    };
  }>;
  groundingSupports?: Array<{
    segment: {
      startIndex: number;
      endIndex: number;
      text: string;
    };
    groundingChunkIndices: number[];
  }>;
  googleMapsWidgetContextToken?: string;
}

// Maps Grounding Function
export const runMapsQuery = async (
  prompt: string,
  location: { latitude: number; longitude: number }
): Promise<{
  text: string;
  places: MapPlace[];
  widgetToken?: string;
}> => {
  try {
    console.log("Starting Maps Query with prompt:", prompt);
    console.log("Location:", location);

    // Crear modelo con Maps Grounding
    // Usamos gemini-2.0-flash para mejor soporte de JSON + Tools
    const ai = await getGenAI();
    const mapsModel = ai.getGenerativeModel({
      model: "gemini-2.5-flash",
    });

    // Construir prompt para JSON
    const jsonPrompt = `
      Act√∫a como un asistente de local y gu√≠a tur√≠stica.
      El usuario est√° en: Lat ${location.latitude}, Lng ${location.longitude}.
      B√∫squeda: "${prompt}".

      Usa la herramienta Google Maps para encontrar lugares reales y relevantes cercanos.
      
      IMPORTANTE: Debes responder EXCLUSIVAMENTE con un objeto JSON v√°lido (sin markdown, sin texto extra) con la siguiente estructura:
      {
        "summary": "Un breve resumen texto de 1 o 2 frases sobre lo encontrado",
        "places": [
          {
            "name": "Nombre del lugar",
            "location": { "lat": 0.0, "lng": 0.0 }, // Coordenadas aproximadas
            "address": "Direcci√≥n corta",
            "rating": 4.5,
            "description": "Breve raz√≥n de por qu√© es bueno",
            "uri": "URL de Google Maps si est√° disponible o link de b√∫squeda"
          }
        ]
      }
    `;

    // Usar generateContent
    // NOTA: No podemos usar responseMimeType: "application/json" junto con tools (Search/Maps) en la misma request actualmente.
    // Dependemos del prompt para obtener JSON.
    const result = await (mapsModel as any).generateContent({
      contents: [{
        role: "user",
        parts: [{ text: jsonPrompt }]
      }],
      tools: [{ googleMaps: {} }]
    });

    const response = result.response;
    const textData = response.text();
    console.log("Maps JSON Response:", textData);

    let parsedData: { summary: string; places: any[] } = { summary: '', places: [] };
    
    try {
        parsedData = JSON.parse(textData);
    } catch (e) {
        console.error("Error parsing Maps JSON:", e);
        // Fallback simple parsing if model adds markdown blocks
        const match = textData.match(/\{[\s\S]*\}/);
        if (match) {
            try {
                parsedData = JSON.parse(match[0]);
            } catch (e2) {
                return { text: "No pude procesar los resultados del mapa.", places: [] };
            }
        } else {
             return { text: "Hubo un error interpretando los datos del mapa.", places: [] };
        }
    }

    const places: MapPlace[] = parsedData.places.map((p: any) => ({
        name: p.name,
        location: p.location, // { lat, lng }
        address: p.address,
        rating: p.rating,
        uri: p.uri || `https://www.google.com/maps/search/?api=1&query=${encodeURIComponent(p.name)}`
    }));

    return {
      text: parsedData.summary || `Encontr√© ${places.length} lugares cercanos.`,
      places,
      widgetToken: undefined 
    };

  } catch (error) {
    console.error("Maps Query error:", error);
    throw error;
  }
};

// Keywords para detectar consultas de Maps/Ubicaci√≥n
export const MAPS_KEYWORDS = [
  // B√∫squeda de lugares
  'cerca', 'cercano', 'cercana', 'cercanos', 'cercanas',
  'donde hay', 'd√≥nde hay', 'donde encuentro', 'd√≥nde encuentro',
  'donde queda', 'd√≥nde queda', 'donde est√°', 'd√≥nde est√°',
  // Tipos de lugares
  'restaurante', 'restaurantes', 'cafe', 'caf√©', 'cafeter√≠a', 'cafeterias',
  'tienda', 'tiendas', 'supermercado', 'supermercados',
  'farmacia', 'farmacias', 'hospital', 'hospitales', 'cl√≠nica', 'clinica',
  'banco', 'bancos', 'cajero', 'cajeros', 'atm',
  'gasolinera', 'gasolineras', 'estaci√≥n de servicio',
  'estacionamiento', 'parking', 'parqueo',
  'hotel', 'hoteles', 'hostal', 'hospedaje',
  'gimnasio', 'gimnasios', 'gym',
  'parque', 'parques', 'plaza', 'plazas',
  'cine', 'cines', 'teatro', 'teatros',
  'bar', 'bares', 'antro', 'club', 'discoteca',
  // Servicios
  'mec√°nico', 'mecanico', 'taller', 'talleres',
  'veterinaria', 'veterinario', 'pet shop',
  'barber√≠a', 'barberia', 'peluquer√≠a', 'peluqueria', 'sal√≥n', 'salon',
  'dentista', 'doctor', 'm√©dico', 'medico',
  // Comida espec√≠fica
  'pizza', 'pizzer√≠a', 'pizzeria', 'hamburguesa', 'hamburguesas',
  'tacos', 'taquer√≠a', 'taqueria', 'sushi', 'comida china', 'comida japonesa',
  'comida italiana', 'comida mexicana', 'mariscos',
  // Acciones de ubicaci√≥n
  'llegar a', 'c√≥mo llego', 'como llego', 'ruta a', 'ruta hacia',
  'direcciones a', 'indicaciones a', 'camino a',
  // Distancia/tiempo
  'minutos caminando', 'minutos en carro', 'minutos en auto',
  'a pie', 'caminando', 'en bicicleta', 'en coche', 'en carro',
  // Preguntas de ubicaci√≥n
  'qu√© hay cerca', 'que hay cerca', 'lugares cerca', 'sitios cerca',
  'recomendaciones cerca', 'opciones cerca'
];

// Detectar si necesita Maps Grounding
export const needsMapsGrounding = (prompt: string): boolean => {
  const lowerPrompt = prompt.toLowerCase();
  return MAPS_KEYWORDS.some(keyword => lowerPrompt.includes(keyword));
};

export const optimizePrompt = async (originalPrompt: string, targetAI: 'chatgpt' | 'claude' | 'gemini'): Promise<string> => {
  const systemInstruction = PROMPT_OPTIMIZER[targetAI];

  try {
    const proModel = await getProModel();
    const result = await proModel.generateContent({
      contents: [
        { role: "user", parts: [{ text: `${systemInstruction}\n\nPROMPT ORIGINAL (A optimizar):\n"${originalPrompt}"\n\nGenera SOLAMENTE el prompt optimizado final:` }] }
      ]
    });

    return result.response.text();
  } catch (error) {
    console.error("Error optimizing prompt:", error);
    throw error;
  }
};

export const transcribeAudio = async (base64Audio: string): Promise<string> => {
  try {
    // Usamos el modelo primario que debe ser capaz de multimodalidad (Gemini 1.5/2.0 Flash)
    const primaryModel = await getPrimaryModel();
    const result = await primaryModel.generateContent({
      contents: [{
        role: "user",
        parts: [
          { inlineData: { mimeType: "audio/webm", data: base64Audio } },
          { text: AUDIO_TRANSCRIPTION_PROMPT }
        ]
      }]
    });
    return result.response.text();
  } catch (error) {
    console.error("Audio transcription error:", error);
    throw error;
  }
};
